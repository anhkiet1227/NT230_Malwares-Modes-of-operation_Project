# Malware project 

This project explores the effectiveness of perturbation in generating evasive malware variants and evaluates the performance of a machine learning model trained on the original and perturbed datasets. 

## Dependencies

- Python 3.7 or higher (in this project is python 3.8.10)
- See requirements.txt for Python package dependencies

## Installation

1. Clone the repository: 

2. Install the required Python packages: `pip install -r requirements.txt`

## Usage

1. Run `notebooks/data_preparation.ipynb` to preprocess the malware dataset.
2. Run `notebooks/evaluation.ipynb` to train and evaluate a machine learning to make the target model.
3. Run `utils/perturbation.py` to generate perturbed samples of the malware.

Note: For each step check the output of when finish running

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.

## Acknowledgments

This project is based on the paper "AIMED-RL: Exploring Adversarial Malware Examples with Reinforcement Learning" and "On the Effectiveness of Perturbations in Generating Evasive Malware Variants"